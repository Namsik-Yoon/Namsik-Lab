{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch import optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(root ='train/',\n",
    "                               transform=transforms.Compose([transforms.Resize(256),\n",
    "                                                             transforms.ColorJitter(),\n",
    "                                                             transforms.RandomCrop(224),\n",
    "                                                             transforms.RandomHorizontalFlip(),\n",
    "                                                             transforms.Resize(128),\n",
    "                                                             transforms.ToTensor(),\n",
    "                                                             transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])\n",
    "                               ]))\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset,[int(len(dataset)*0.8),int(len(dataset)*0.2)])\n",
    "\n",
    "train_dataloader = DataLoader(train_set,batch_size=512,\n",
    "                        shuffle=True,num_workers=8,\n",
    "                        drop_last=True,pin_memory=True)\n",
    "\n",
    "val_dataloader = DataLoader(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)\n",
    "for p in vgg16.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_featrues = num_features = vgg16.classifier[6].in_features\n",
    "features = list(vgg16.classifier.children())[:-1]\n",
    "features.extend([nn.Linear(num_features, 2)])\n",
    "vgg16.classifier = nn.Sequential(*features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = vgg16.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch train loss = 0.1267513930797577\n",
      "1 epoch val loss = 0.06851354241371155\n",
      "1 epoch accuracy = 0.9744\n",
      "--------------------------------------------------\n",
      "2 epoch train loss = 0.07510467618703842\n",
      "2 epoch val loss = 0.0647452101111412\n",
      "2 epoch accuracy = 0.9748\n",
      "--------------------------------------------------\n",
      "3 epoch train loss = 0.0728272944688797\n",
      "3 epoch val loss = 0.058975204825401306\n",
      "3 epoch accuracy = 0.976\n",
      "--------------------------------------------------\n",
      "4 epoch train loss = 0.06776028871536255\n",
      "4 epoch val loss = 0.06174173951148987\n",
      "4 epoch accuracy = 0.9764\n",
      "--------------------------------------------------\n",
      "5 epoch train loss = 0.06574101746082306\n",
      "5 epoch val loss = 0.06877242773771286\n",
      "5 epoch accuracy = 0.9714\n",
      "--------------------------------------------------\n",
      "6 epoch train loss = 0.06959791481494904\n",
      "6 epoch val loss = 0.05596082657575607\n",
      "6 epoch accuracy = 0.9778\n",
      "--------------------------------------------------\n",
      "7 epoch train loss = 0.06382209062576294\n",
      "7 epoch val loss = 0.060064055025577545\n",
      "7 epoch accuracy = 0.976\n",
      "--------------------------------------------------\n",
      "8 epoch train loss = 0.06611116230487823\n",
      "8 epoch val loss = 0.06643131375312805\n",
      "8 epoch accuracy = 0.972\n",
      "--------------------------------------------------\n",
      "9 epoch train loss = 0.06402712315320969\n",
      "9 epoch val loss = 0.06102500483393669\n",
      "9 epoch accuracy = 0.9758\n",
      "--------------------------------------------------\n",
      "10 epoch train loss = 0.06509285420179367\n",
      "10 epoch val loss = 0.06473945826292038\n",
      "10 epoch accuracy = 0.9746\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "plot_list = {'train':[],'val':[],'accuracy':[]}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for i,data in enumerate(train_dataloader):\n",
    "        inputs,targets = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs.detach())\n",
    "        train_loss = criterion(outputs,targets)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(train_loss.detach()) ## train_loss를 detach하지않으면 gpu에 계속 남아서 메모리를 잡아먹음...\n",
    "                                                 ## 진짜 애많이먹었습니다....\n",
    "                                                 ## data와 inputs도 혹시모르니...삭제\n",
    "        del data\n",
    "        del inputs\n",
    "        \n",
    "    \n",
    "    val_losses = []\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    for data in val_dataloader:\n",
    "        inputs,targets = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        val_loss = criterion(outputs,targets)\n",
    "        val_losses.append(val_loss.detach())\n",
    "\n",
    "        prob,label = torch.exp(outputs).topk(1,dim=1)\n",
    "        if targets==label.view(1):\n",
    "            correct+=1\n",
    "        del data\n",
    "        del inputs\n",
    "    val_accuracy = correct/len(val_set)\n",
    "    \n",
    "    print(f\"{epoch+1} epoch train loss = {sum(train_losses)/len(train_losses)}\")\n",
    "    print(f\"{epoch+1} epoch val loss = {sum(val_losses)/len(val_losses)}\")\n",
    "    print(f\"{epoch+1} epoch accuracy = {val_accuracy}\")\n",
    "    print('--------------------------------------------------')\n",
    "    plot_list['train'].append(sum(train_losses)/len(train_losses))\n",
    "    plot_list['val'].append(sum(val_losses)/len(val_losses))\n",
    "    plot_list['accuracy'].append(val_accuracy)\n",
    "    \n",
    "#     if epoch < 11:continue\n",
    "#     if sum(plot_list['val'][-11:-6])/5 < sum(val_losses)/len(val_losses):\n",
    "#         print(f'over_fitting is occured at {epoch} epoch')\n",
    "#         break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
